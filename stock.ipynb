{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d7efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\120555688.py:23: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers=stocks, start=start, end=end)\n",
      "[*****                 10%                       ]  2 of 20 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading stock data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  20 of 20 completed\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\120555688.py:46: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ticker = df_ticker[['Open', 'High', 'Low', 'Close']].fillna(method=\"ffill\")\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\120555688.py:49: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ticker[\"SMA30\"] = df_ticker[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
      "c:\\Users\\user\\OneDrive - City University\\Desktop\\Python B\\.conda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing AAPL...\n",
      "   Data shape for AAPL: (2096, 60, 5)\n",
      "   Training AAPL model...\n",
      "Epoch 1/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0193\n",
      "Epoch 1: val_loss improved from None to 0.02137, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - loss: 0.0087 - val_loss: 0.0214\n",
      "Epoch 2/100\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0028\n",
      "Epoch 2: val_loss improved from 0.02137 to 0.00289, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 3/100\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0021\n",
      "Epoch 3: val_loss did not improve from 0.00289\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 4/100\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0022\n",
      "Epoch 4: val_loss improved from 0.00289 to 0.00236, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 5/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0020\n",
      "Epoch 5: val_loss improved from 0.00236 to 0.00223, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 6/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0020\n",
      "Epoch 6: val_loss did not improve from 0.00223\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0020 - val_loss: 0.0211\n",
      "Epoch 7/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0026\n",
      "Epoch 7: val_loss did not improve from 0.00223\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 8/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0021\n",
      "Epoch 8: val_loss did not improve from 0.00223\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 9/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0018\n",
      "Epoch 9: val_loss did not improve from 0.00223\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 10/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0015\n",
      "Epoch 10: val_loss improved from 0.00223 to 0.00184, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 124ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 11/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0015\n",
      "Epoch 11: val_loss did not improve from 0.00184\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 132ms/step - loss: 0.0015 - val_loss: 0.0062\n",
      "Epoch 12/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0015\n",
      "Epoch 12: val_loss did not improve from 0.00184\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 132ms/step - loss: 0.0015 - val_loss: 0.0050\n",
      "Epoch 13/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0013\n",
      "Epoch 13: val_loss did not improve from 0.00184\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 132ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 14/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0018\n",
      "Epoch 14: val_loss did not improve from 0.00184\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 138ms/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 15/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0014\n",
      "Epoch 15: val_loss did not improve from 0.00184\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 136ms/step - loss: 0.0019 - val_loss: 0.0103\n",
      "Epoch 16/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0017\n",
      "Epoch 16: val_loss improved from 0.00184 to 0.00157, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 127ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 17/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0016\n",
      "Epoch 17: val_loss did not improve from 0.00157\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 18/100\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0014\n",
      "Epoch 18: val_loss did not improve from 0.00157\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 19/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0013\n",
      "Epoch 19: val_loss did not improve from 0.00157\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 0.0012 - val_loss: 0.0058\n",
      "Epoch 20/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0012\n",
      "Epoch 20: val_loss did not improve from 0.00157\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 21/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0010\n",
      "Epoch 21: val_loss did not improve from 0.00157\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 22/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0011\n",
      "Epoch 22: val_loss did not improve from 0.00157\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 23/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0014\n",
      "Epoch 23: val_loss did not improve from 0.00157\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.0013 - val_loss: 0.0047\n",
      "Epoch 24/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0011\n",
      "Epoch 24: val_loss improved from 0.00157 to 0.00130, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 25/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0012\n",
      "Epoch 25: val_loss did not improve from 0.00130\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 26/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0013\n",
      "Epoch 26: val_loss did not improve from 0.00130\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 27/100\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 9.5005e-04\n",
      "Epoch 27: val_loss did not improve from 0.00130\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 28/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0011\n",
      "Epoch 28: val_loss did not improve from 0.00130\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0010\n",
      "Epoch 29: val_loss improved from 0.00130 to 0.00124, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 9.0797e-04\n",
      "Epoch 30: val_loss did not improve from 0.00124\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 9.1919e-04 - val_loss: 0.0060\n",
      "Epoch 31/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0012\n",
      "Epoch 31: val_loss did not improve from 0.00124\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 32/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0012\n",
      "Epoch 32: val_loss did not improve from 0.00124\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 33/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 9.1637e-04\n",
      "Epoch 33: val_loss did not improve from 0.00124\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 8.8021e-04 - val_loss: 0.0025\n",
      "Epoch 34/100\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 9.6539e-04\n",
      "Epoch 34: val_loss improved from 0.00124 to 0.00118, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 9.7760e-04 - val_loss: 0.0012\n",
      "Epoch 35/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 9.6780e-04\n",
      "Epoch 35: val_loss improved from 0.00118 to 0.00104, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 9.2749e-04 - val_loss: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 9.2491e-04\n",
      "Epoch 36: val_loss did not improve from 0.00104\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 37/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0012\n",
      "Epoch 37: val_loss did not improve from 0.00104\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 38/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0010\n",
      "Epoch 38: val_loss did not improve from 0.00104\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 9.7165e-04 - val_loss: 0.0012\n",
      "Epoch 39/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 8.8750e-04\n",
      "Epoch 39: val_loss did not improve from 0.00104\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 9.9688e-04 - val_loss: 0.0015\n",
      "Epoch 40/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 9.2241e-04\n",
      "Epoch 40: val_loss did not improve from 0.00104\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 9.6501e-04 - val_loss: 0.0041\n",
      "Epoch 41/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 9.5435e-04\n",
      "Epoch 41: val_loss did not improve from 0.00104\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 9.1304e-04 - val_loss: 0.0016\n",
      "Epoch 42/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0011\n",
      "Epoch 42: val_loss did not improve from 0.00104\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 43/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 9.5066e-04\n",
      "Epoch 43: val_loss improved from 0.00104 to 0.00101, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 9.3287e-04 - val_loss: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0010\n",
      "Epoch 44: val_loss did not improve from 0.00101\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 45/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 8.9607e-04\n",
      "Epoch 45: val_loss did not improve from 0.00101\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 8.6544e-04 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0010\n",
      "Epoch 46: val_loss did not improve from 0.00101\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 9.6521e-04 - val_loss: 0.0057\n",
      "Epoch 47/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 9.8028e-04\n",
      "Epoch 47: val_loss did not improve from 0.00101\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 9.9515e-04 - val_loss: 0.0031\n",
      "Epoch 48/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 9.1201e-04\n",
      "Epoch 48: val_loss did not improve from 0.00101\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 8.7855e-04 - val_loss: 0.0020\n",
      "Epoch 49/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 9.0620e-04\n",
      "Epoch 49: val_loss did not improve from 0.00101\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 9.2723e-04 - val_loss: 0.0029\n",
      "Epoch 50/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 8.5519e-04\n",
      "Epoch 50: val_loss improved from 0.00101 to 0.00095, saving model to AAPL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 8.4178e-04 - val_loss: 9.5401e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0011\n",
      "Epoch 51: val_loss did not improve from 0.00095\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 8.8348e-04\n",
      "Epoch 52: val_loss did not improve from 0.00095\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 9.0868e-04 - val_loss: 0.0016\n",
      "Epoch 53/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0010\n",
      "Epoch 53: val_loss did not improve from 0.00095\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 54/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 8.5391e-04\n",
      "Epoch 54: val_loss did not improve from 0.00095\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 8.5201e-04 - val_loss: 0.0038\n",
      "Epoch 55/100\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 9.2484e-04\n",
      "Epoch 55: val_loss did not improve from 0.00095\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 9.0155e-04 - val_loss: 0.0019\n",
      "Epoch 56/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 9.1679e-04\n",
      "Epoch 56: val_loss did not improve from 0.00095\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 8.7799e-04 - val_loss: 0.0022\n",
      "Epoch 57/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 8.8712e-04\n",
      "Epoch 57: val_loss did not improve from 0.00095\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 8.9733e-04 - val_loss: 0.0013\n",
      "Epoch 58/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 8.7608e-04\n",
      "Epoch 58: val_loss did not improve from 0.00095\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - loss: 8.4315e-04 - val_loss: 0.0014\n",
      "Epoch 59/100\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 8.3190e-04\n",
      "Epoch 59: val_loss did not improve from 0.00095\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - loss: 8.4092e-04 - val_loss: 0.0020\n",
      "Epoch 60/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 9.2934e-04\n",
      "Epoch 60: val_loss did not improve from 0.00095\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 8.4354e-04 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed AAPL\n",
      "🚀 Processing MSFT...\n",
      "   Data shape for MSFT: (2096, 60, 5)\n",
      "   Training MSFT model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\120555688.py:46: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ticker = df_ticker[['Open', 'High', 'Low', 'Close']].fillna(method=\"ffill\")\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\120555688.py:49: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ticker[\"SMA30\"] = df_ticker[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
      "c:\\Users\\user\\OneDrive - City University\\Desktop\\Python B\\.conda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0149\n",
      "Epoch 1: val_loss improved from None to 0.00509, saving model to MSFT_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 2/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0021\n",
      "Epoch 2: val_loss did not improve from 0.00509\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0018 - val_loss: 0.0111\n",
      "Epoch 3/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0017\n",
      "Epoch 3: val_loss did not improve from 0.00509\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0017 - val_loss: 0.0057\n",
      "Epoch 4/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0016\n",
      "Epoch 4: val_loss improved from 0.00509 to 0.00505, saving model to MSFT_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 5/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0018\n",
      "Epoch 5: val_loss improved from 0.00505 to 0.00221, saving model to MSFT_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 6/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0016\n",
      "Epoch 6: val_loss did not improve from 0.00221\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 7/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0014\n",
      "Epoch 7: val_loss did not improve from 0.00221\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.0015 - val_loss: 0.0117\n",
      "Epoch 8/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0013\n",
      "Epoch 8: val_loss did not improve from 0.00221\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 9/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0011\n",
      "Epoch 9: val_loss improved from 0.00221 to 0.00145, saving model to MSFT_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 10/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0011\n",
      "Epoch 10: val_loss did not improve from 0.00145\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 11/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0012\n",
      "Epoch 11: val_loss did not improve from 0.00145\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 12/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0011\n",
      "Epoch 12: val_loss did not improve from 0.00145\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 13/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0011\n",
      "Epoch 13: val_loss improved from 0.00145 to 0.00121, saving model to MSFT_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 9.6910e-04\n",
      "Epoch 14: val_loss did not improve from 0.00121\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 9.4872e-04 - val_loss: 0.0027\n",
      "Epoch 15/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0011\n",
      "Epoch 15: val_loss did not improve from 0.00121\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 16/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0011\n",
      "Epoch 16: val_loss did not improve from 0.00121\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 17/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 9.6504e-04\n",
      "Epoch 17: val_loss did not improve from 0.00121\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - loss: 9.6758e-04 - val_loss: 0.0073\n",
      "Epoch 18/100\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 8.8106e-04\n",
      "Epoch 18: val_loss did not improve from 0.00121\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 9.3542e-04 - val_loss: 0.0032\n",
      "Epoch 19/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 9.4640e-04\n",
      "Epoch 19: val_loss did not improve from 0.00121\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - loss: 9.3162e-04 - val_loss: 0.0013\n",
      "Epoch 20/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0010\n",
      "Epoch 20: val_loss did not improve from 0.00121\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 177ms/step - loss: 9.0774e-04 - val_loss: 0.0028\n",
      "Epoch 21/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 8.9132e-04\n",
      "Epoch 21: val_loss did not improve from 0.00121\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - loss: 8.7014e-04 - val_loss: 0.0021\n",
      "Epoch 22/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0010\n",
      "Epoch 22: val_loss did not improve from 0.00121\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - loss: 9.4540e-04 - val_loss: 0.0043\n",
      "Epoch 23/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 7.9029e-04\n",
      "Epoch 23: val_loss did not improve from 0.00121\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 7.7791e-04 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Completed MSFT\n",
      "🚀 Processing GOOGL...\n",
      "   Data shape for GOOGL: (2096, 60, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\120555688.py:46: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ticker = df_ticker[['Open', 'High', 'Low', 'Close']].fillna(method=\"ffill\")\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\120555688.py:49: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ticker[\"SMA30\"] = df_ticker[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
      "c:\\Users\\user\\OneDrive - City University\\Desktop\\Python B\\.conda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training GOOGL model...\n",
      "Epoch 1/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0167\n",
      "Epoch 1: val_loss improved from None to 0.00433, saving model to GOOGL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 201ms/step - loss: 0.0078 - val_loss: 0.0043\n",
      "Epoch 2/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0023\n",
      "Epoch 2: val_loss improved from 0.00433 to 0.00204, saving model to GOOGL_best_lstm_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 182ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 3/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0021\n",
      "Epoch 3: val_loss did not improve from 0.00204\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 177ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 4/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0018\n",
      "Epoch 4: val_loss did not improve from 0.00204\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 179ms/step - loss: 0.0018 - val_loss: 0.0097\n",
      "Epoch 5/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.0017\n",
      "Epoch 5: val_loss did not improve from 0.00204\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 6/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0017"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import date \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Stock list for 20 companies\n",
    "stocks = [\"AAPL\",\"MSFT\",\"GOOGL\",\"AMZN\",\"META\",\"TSLA\",\"NFLX\",\"NVDA\",\"INTC\",\"AMD\",\"BABA\",\n",
    "          \"ORCL\",\"PYPL\",\"ADBE\",\"CRM\",\"IBM\",\"KO\",\"PEP\",\"DIS\",\"UBER\"]\n",
    "\n",
    "start = \"2015-01-01\"\n",
    "end   = date.today().strftime(\"%Y-%m-%d\")\n",
    "print(\"Downloading stock data...\")\n",
    "\n",
    "# Download data for all stocks\n",
    "data = yf.download(tickers=stocks, start=start, end=end)\n",
    "data = data[['Open', 'High', 'Low', 'Close']]\n",
    "\n",
    "# Dictionaries to store results\n",
    "models = {}      \n",
    "scalers = {}      \n",
    "histories = {}  \n",
    "predictions = {}  \n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(dataset, lookback=60):\n",
    "    x, y = [], []\n",
    "    for i in range(lookback, len(dataset)):\n",
    "        x.append(dataset[i-lookback:i, :])   # all features (OHLC + SMA30)\n",
    "        y.append(dataset[i, 3])              # 3rd index = Close\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "for ticker in stocks:\n",
    "    print(f\"🚀 Processing {ticker}...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract OHLC for one ticker - CORRECTED\n",
    "        df_ticker = data.xs(ticker, level=1, axis=1)\n",
    "        df_ticker = df_ticker[['Open', 'High', 'Low', 'Close']].fillna(method=\"ffill\")\n",
    "        \n",
    "        # Add SMA30\n",
    "        df_ticker[\"SMA30\"] = df_ticker[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
    "        \n",
    "        # Create a new scaler for EACH ticker\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaled_data = scaler.fit_transform(df_ticker)\n",
    "        \n",
    "        # Save scaler for this ticker\n",
    "        scalers[ticker] = scaler\n",
    "        joblib.dump(scaler, f\"{ticker}_scaler.save\")\n",
    "        \n",
    "        # Sequence creation\n",
    "        x, y = create_sequences(scaled_data, 60)\n",
    "        \n",
    "        # Train-test split\n",
    "        train_size = int(len(x) * 0.8)\n",
    "        x_train, x_test = x[:train_size], x[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "        \n",
    "        print(f\"   Data shape for {ticker}: {x_train.shape}\")\n",
    "        \n",
    "        # Build model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(60, return_sequences=True))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(80, return_sequences=True))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(LSTM(120))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        checkpoint = ModelCheckpoint(f\"{ticker}_best_lstm_model.h5\", monitor='val_loss',\n",
    "                                     save_best_only=True, verbose=1)\n",
    "        \n",
    "        # Train model\n",
    "        print(f\"   Training {ticker} model...\")\n",
    "        history = model.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=100,  # Reduced for testing, you can increase later\n",
    "            batch_size=32,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[early_stop, checkpoint],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Save model and history\n",
    "        model.save(f\"{ticker}_lstm_model.h5\")\n",
    "        models[ticker] = model\n",
    "        histories[ticker] = history\n",
    "        \n",
    "        print(f\"✅ Completed {ticker}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {ticker}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STARTING MODEL TESTING\n",
      "==================================================\n",
      "Testing AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\621903705.py:32: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  test_data = yf.download(ticker, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\621903705.py:36: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_data[\"SMA30\"] = test_data[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
      "c:\\Users\\user\\OneDrive - City University\\Desktop\\Python B\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
      " AAPL Test Results:\n",
      "   MSE: 91.1733, MAE: 7.4554, RMSE: 9.5485\n",
      "   R² Score: 0.8478\n",
      "   Direction Accuracy: 49.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MSFT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\621903705.py:32: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  test_data = yf.download(ticker, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\621903705.py:36: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_data[\"SMA30\"] = test_data[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
      "c:\\Users\\user\\OneDrive - City University\\Desktop\\Python B\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
      " MSFT Test Results:\n",
      "   MSE: 222.0809, MAE: 11.7250, RMSE: 14.9024\n",
      "   R² Score: 0.9325\n",
      "   Direction Accuracy: 49.01%\n",
      "Testing GOOGL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\621903705.py:32: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  test_data = yf.download(ticker, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\621903705.py:36: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_data[\"SMA30\"] = test_data[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
      "c:\\Users\\user\\OneDrive - City University\\Desktop\\Python B\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
      " GOOGL Test Results:\n",
      "   MSE: 54.5105, MAE: 5.8444, RMSE: 7.3831\n",
      "   R² Score: 0.9161\n",
      "   Direction Accuracy: 52.48%\n",
      "Testing AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\621903705.py:32: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  test_data = yf.download(ticker, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\621903705.py:36: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_data[\"SMA30\"] = test_data[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
      "c:\\Users\\user\\OneDrive - City University\\Desktop\\Python B\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
      " AMZN Test Results:\n",
      "   MSE: 42.3150, MAE: 4.9060, RMSE: 6.5050\n",
      "   R² Score: 0.9684\n",
      "   Direction Accuracy: 47.69%\n",
      "\n",
      "============================================================\n",
      "SUMMARY OF ALL MODEL PERFORMANCES\n",
      "============================================================\n",
      "              mse        mae       rmse        r2  direction_accuracy\n",
      "AMZN    42.315000   4.906004   6.504998  0.968392           47.689769\n",
      "GOOGL   54.510515   5.844412   7.383124  0.916050           52.475248\n",
      "AAPL    91.173337   7.455372   9.548473  0.847794           49.009901\n",
      "MSFT   222.080926  11.725040  14.902380  0.932498           49.009901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 Predicting next 30 days for AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\621903705.py:155: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  recent_data = yf.download(ticker, start=start_date, end=end_date)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8208\\621903705.py:159: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  recent_data[\"SMA30\"] = recent_data[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
      "c:\\Users\\user\\OneDrive - City University\\Desktop\\Python B\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future predictions saved for AAPL\n",
      "\n",
      "Testing completed! Check the generated charts and CSV files for results.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from datetime import date, timedelta\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to create sequences (same as training)\n",
    "def create_sequences(dataset, lookback=60):\n",
    "    x, y = [], []\n",
    "    for i in range(lookback, len(dataset)):\n",
    "        x.append(dataset[i-lookback:i, :])   # all features (OHLC + SMA30)\n",
    "        y.append(dataset[i, 3])              # 3rd index = Close\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# Function to test a single model\n",
    "def test_model(ticker, start_date=\"2023-01-01\", end_date=None):\n",
    "    if end_date is None:\n",
    "        end_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    print(f\"Testing {ticker}...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the saved model and scaler\n",
    "        model = load_model(f\"{ticker}_lstm_model.h5\")\n",
    "        scaler = joblib.load(f\"{ticker}_scaler.save\")\n",
    "        \n",
    "        # Download fresh data for testing period\n",
    "        test_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        test_data = test_data[['Open', 'High', 'Low', 'Close']]\n",
    "        \n",
    "        # Add SMA30\n",
    "        test_data[\"SMA30\"] = test_data[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
    "        \n",
    "        # Scale the test data using the same scaler\n",
    "        scaled_test_data = scaler.transform(test_data)\n",
    "        \n",
    "        # Create sequences for testing\n",
    "        x_test, y_test = create_sequences(scaled_test_data, 60)\n",
    "        \n",
    "        if len(x_test) == 0:\n",
    "            print(f\"Not enough data to test {ticker}\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(x_test)\n",
    "        \n",
    "        # Inverse transform predictions and actual values\n",
    "        # Create dummy arrays for inverse transformation\n",
    "        dummy_array_pred = np.zeros((len(predictions), scaled_test_data.shape[1]))\n",
    "        dummy_array_pred[:, 3] = predictions.flatten()  # Close price is at index 3\n",
    "        predictions_actual = scaler.inverse_transform(dummy_array_pred)[:, 3]\n",
    "        \n",
    "        dummy_array_actual = np.zeros((len(y_test), scaled_test_data.shape[1]))\n",
    "        dummy_array_actual[:, 3] = y_test\n",
    "        y_test_actual = scaler.inverse_transform(dummy_array_actual)[:, 3]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test_actual, predictions_actual)\n",
    "        mae = mean_absolute_error(y_test_actual, predictions_actual)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test_actual, predictions_actual)\n",
    "        \n",
    "        # Calculate accuracy (percentage of correct direction predictions)\n",
    "        direction_accuracy = np.mean(\n",
    "            (np.sign(predictions_actual[1:] - predictions_actual[:-1]) == \n",
    "             np.sign(y_test_actual[1:] - y_test_actual[:-1])).astype(int)\n",
    "        ) * 100\n",
    "        \n",
    "        print(f\" {ticker} Test Results:\")\n",
    "        print(f\"   MSE: {mse:.4f}, MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "        print(f\"   R² Score: {r2:.4f}\")\n",
    "        print(f\"   Direction Accuracy: {direction_accuracy:.2f}%\")\n",
    "        \n",
    "        # Plot results\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(test_data.index[60:60+len(y_test_actual)], y_test_actual, label='Actual', linewidth=2)\n",
    "        plt.plot(test_data.index[60:60+len(predictions_actual)], predictions_actual, label='Predicted', linewidth=2)\n",
    "        plt.title(f'{ticker} Stock Price Prediction')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price ($)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"{ticker}_prediction_test.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Save results to CSV\n",
    "        results_df = pd.DataFrame({\n",
    "            'Date': test_data.index[60:60+len(y_test_actual)],\n",
    "            'Actual': y_test_actual,\n",
    "            'Predicted': predictions_actual\n",
    "        })\n",
    "        results_df.to_csv(f\"{ticker}_test_results.csv\", index=False)\n",
    "        \n",
    "        return y_test_actual, predictions_actual, {\n",
    "            'mse': mse, 'mae': mae, 'rmse': rmse, 'r2': r2, 'direction_accuracy': direction_accuracy\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing {ticker}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Function to test all models\n",
    "def test_all_models(start_date=\"2023-01-01\", end_date=None):\n",
    "    results = {}\n",
    "    \n",
    "    for ticker in stocks:\n",
    "        try:\n",
    "            actual, predicted, metrics = test_model(ticker, start_date, end_date)\n",
    "            if metrics:\n",
    "                results[ticker] = metrics\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Print summary of all results\n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SUMMARY OF ALL MODEL PERFORMANCES\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        results_df = pd.DataFrame(results).T\n",
    "        results_df = results_df.sort_values('rmse')\n",
    "        \n",
    "        print(results_df)\n",
    "        \n",
    "        # Plot comparison of RMSE values\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        results_df['rmse'].sort_values().plot(kind='barh')\n",
    "        plt.title('RMSE Comparison Across Stocks')\n",
    "        plt.xlabel('RMSE')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"all_models_rmse_comparison.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Save summary results\n",
    "        results_df.to_csv(\"all_models_test_results.csv\")\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Function to predict future prices\n",
    "def predict_future(ticker, days=30):\n",
    "    print(f\"🔮 Predicting next {days} days for {ticker}...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the saved model and scaler\n",
    "        model = load_model(f\"{ticker}_lstm_model.h5\")\n",
    "        scaler = joblib.load(f\"{ticker}_scaler.save\")\n",
    "        \n",
    "        # Download recent data (last 60+ days)\n",
    "        end_date = date.today()\n",
    "        start_date = end_date - timedelta(days=120)  # Get more data than needed\n",
    "        recent_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        recent_data = recent_data[['Open', 'High', 'Low', 'Close']]\n",
    "        \n",
    "        # Add SMA30\n",
    "        recent_data[\"SMA30\"] = recent_data[\"Close\"].rolling(window=30).mean().fillna(method=\"bfill\")\n",
    "        \n",
    "        # Get the last 60 days of data\n",
    "        last_60_days = recent_data.iloc[-60:].copy()\n",
    "        scaled_data = scaler.transform(last_60_days)\n",
    "        \n",
    "        future_predictions = []\n",
    "        current_sequence = scaled_data.copy()\n",
    "        \n",
    "        for _ in range(days):\n",
    "            # Reshape the sequence for prediction\n",
    "            x = current_sequence[-60:].reshape(1, 60, scaled_data.shape[1])\n",
    "            \n",
    "            # Predict next day\n",
    "            next_pred = model.predict(x, verbose=0)\n",
    "            \n",
    "            # Create a new row for the prediction\n",
    "            new_row = current_sequence[-1].copy()  # Copy the last row\n",
    "            new_row[3] = next_pred[0, 0]  # Update the Close price\n",
    "            \n",
    "            # For other features, we can use simple assumptions\n",
    "            # In a real application, you might want to predict these too or use better methods\n",
    "            new_row[0] = new_row[3] * 0.99  # Open slightly lower than close\n",
    "            new_row[1] = new_row[3] * 1.01  # High slightly higher than close\n",
    "            new_row[2] = new_row[3] * 0.98  # Low slightly lower than close\n",
    "            \n",
    "            # Append to sequence and future predictions\n",
    "            current_sequence = np.vstack([current_sequence, new_row])\n",
    "            future_predictions.append(new_row)\n",
    "        \n",
    "        # Inverse transform the future predictions\n",
    "        future_predictions = np.array(future_predictions)\n",
    "        future_predictions_actual = scaler.inverse_transform(future_predictions)[:, 3]  # Close prices\n",
    "        \n",
    "        # Create future dates\n",
    "        last_date = recent_data.index[-1]\n",
    "        future_dates = [last_date + timedelta(days=i) for i in range(1, days+1)]\n",
    "        \n",
    "        # Plot historical and future predictions\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(recent_data.index[-60:], recent_data['Close'][-60:], label='Historical', linewidth=2)\n",
    "        plt.plot(future_dates, future_predictions_actual, label='Predicted', linewidth=2, color='red')\n",
    "        plt.title(f'{ticker} Future Price Prediction (Next {days} Days)')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price ($)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{ticker}_future_prediction.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        future_df = pd.DataFrame({\n",
    "            'Date': future_dates,\n",
    "            'Predicted_Close': future_predictions_actual\n",
    "        })\n",
    "        \n",
    "        future_df.to_csv(f\"{ticker}_future_predictions.csv\", index=False)\n",
    "        \n",
    "        print(f\"Future predictions saved for {ticker}\")\n",
    "        return future_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting future for {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main execution for testing\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STARTING MODEL TESTING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test all models\n",
    "results = test_all_models()\n",
    "\n",
    "# Predict future for a specific stock (e.g., AAPL)\n",
    "predict_future(\"AAPL\", days=30)\n",
    "\n",
    "print(\"\\nTesting completed! Check the generated charts and CSV files for results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3706306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
